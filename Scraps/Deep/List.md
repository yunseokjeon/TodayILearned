AI 학습 시간과 데이터를 줄여주는 AI는 작년 초에 이미 나왔다.

여전히 사람이 필요하기 때문에 자가 학습이 시작되는 특이점은 아니지만, 사람의 개입이 줄어드는 속도를 재면 특이점까지의 디데이를 계산할 수 있지 않을까.
[Researchers Build AI That Builds AI](https://www.quantamagazine.org/researchers-build-ai-that-builds-ai-20220125/)

[오전 12:37 · 2023년 1월 21일](https://twitter.com/seodam_hst/status/1616459940671164420)

When Knyazev and his colleagues came upon the graph hypernetwork idea, they realized they could build upon it. In their new paper, the team shows how to use GHNs not just to find the best architecture from some set of samples, but also to predict the parameters for the best network such that it performs well in an absolute sense. And in situations where the best is not good enough, the network can be trained further using gradient descent.
[Researchers Build AI That Builds AI](https://www.quantamagazine.org/researchers-build-ai-that-builds-ai-20220125/)

[Parameter Prediction for Unseen Deep Architectures](https://arxiv.org/abs/2110.13100)

